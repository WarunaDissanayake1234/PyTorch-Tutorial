{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCOAhXh/JSm2XzpEnWOFej",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WarunaDissanayake1234/PyTorch-Tutorial/blob/main/Pytorch_Basic_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eswWUUDOpYEf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definng input size, Hiddin layer size, output size and batch size respectively\n",
        "input_layer_size, hidden_layer_size, output_layer_size, batch_size = 10, 5, 1, 10"
      ],
      "metadata": {
        "id": "M6fvVyP1poqw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating dummy input and target tensors(data)\n",
        "\n",
        "x = torch.randn(batch_size, input_layer_size)\n",
        "y = torch.tensor([[1.0], [0.0], [0.0],\n",
        "[1.0], [1.0], [1.0], [0.0], [0.0], [1.0], [1.0]])"
      ],
      "metadata": {
        "id": "6wTO8FWbqY-8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a model\n",
        "\n",
        "model = nn.Sequential(nn.Linear(input_layer_size, hidden_layer_size),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_layer_size, output_layer_size),\n",
        "                      nn.Sigmoid())"
      ],
      "metadata": {
        "id": "lBct83-1qx_e"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contruct the loss function\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "# Construct the optimizer (Stochastic Gradient Descent in this case)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)"
      ],
      "metadata": {
        "id": "UEoX5VE9rdsd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient desent\n",
        "for epoch in range(50):\n",
        "  # Forward pass: Compute predicted y by passing x to the model\n",
        "  y_pred = model(x)\n",
        "\n",
        "  # Compute and print loss\n",
        "  loss = criterion(y_pred,y)\n",
        "  print('epoch: ', epoch, 'loss: ', loss.item())\n",
        "\n",
        "  # Zero gradients, perform a backward pass, and update the weights.\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # perform a backward pass (backpropagation)\n",
        "  loss.backward()\n",
        "\n",
        "  # update the parameters\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roTuyxEssLc6",
        "outputId": "f597a429-2c35-4003-f615-60036135dc4f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0 loss:  0.25259262323379517\n",
            "epoch:  1 loss:  0.2513110041618347\n",
            "epoch:  2 loss:  0.2500413954257965\n",
            "epoch:  3 loss:  0.24878251552581787\n",
            "epoch:  4 loss:  0.2475331723690033\n",
            "epoch:  5 loss:  0.2462920844554901\n",
            "epoch:  6 loss:  0.2450580596923828\n",
            "epoch:  7 loss:  0.24382999539375305\n",
            "epoch:  8 loss:  0.24270999431610107\n",
            "epoch:  9 loss:  0.2415957748889923\n",
            "epoch:  10 loss:  0.2404830902814865\n",
            "epoch:  11 loss:  0.23937086760997772\n",
            "epoch:  12 loss:  0.2382582128047943\n",
            "epoch:  13 loss:  0.23714414238929749\n",
            "epoch:  14 loss:  0.23602767288684845\n",
            "epoch:  15 loss:  0.23490789532661438\n",
            "epoch:  16 loss:  0.23378388583660126\n",
            "epoch:  17 loss:  0.23265472054481506\n",
            "epoch:  18 loss:  0.23151955008506775\n",
            "epoch:  19 loss:  0.23037751019001007\n",
            "epoch:  20 loss:  0.22922778129577637\n",
            "epoch:  21 loss:  0.2280695140361786\n",
            "epoch:  22 loss:  0.22690196335315704\n",
            "epoch:  23 loss:  0.2257242649793625\n",
            "epoch:  24 loss:  0.22453567385673523\n",
            "epoch:  25 loss:  0.22333545982837677\n",
            "epoch:  26 loss:  0.2221229523420334\n",
            "epoch:  27 loss:  0.22089743614196777\n",
            "epoch:  28 loss:  0.21965822577476501\n",
            "epoch:  29 loss:  0.21840468049049377\n",
            "epoch:  30 loss:  0.2171468436717987\n",
            "epoch:  31 loss:  0.2159237414598465\n",
            "epoch:  32 loss:  0.21467867493629456\n",
            "epoch:  33 loss:  0.21340754628181458\n",
            "epoch:  34 loss:  0.2121245563030243\n",
            "epoch:  35 loss:  0.21084685623645782\n",
            "epoch:  36 loss:  0.20952698588371277\n",
            "epoch:  37 loss:  0.2081899344921112\n",
            "epoch:  38 loss:  0.20685258507728577\n",
            "epoch:  39 loss:  0.20549269020557404\n",
            "epoch:  40 loss:  0.20410184562206268\n",
            "epoch:  41 loss:  0.2026924341917038\n",
            "epoch:  42 loss:  0.2012927234172821\n",
            "epoch:  43 loss:  0.19984742999076843\n",
            "epoch:  44 loss:  0.19838109612464905\n",
            "epoch:  45 loss:  0.1969023048877716\n",
            "epoch:  46 loss:  0.19540664553642273\n",
            "epoch:  47 loss:  0.19375209510326385\n",
            "epoch:  48 loss:  0.1920769214630127\n",
            "epoch:  49 loss:  0.1903812438249588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ECnSFwmstfcS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}